{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty and outlier detection\n",
    "\n",
    "Going through all of the `scikit-learn` methods for outlier detection to see what we get!\n",
    "\n",
    "## Data\n",
    "\n",
    "Import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned data from clean_data.py\n",
    "df = pd.read_csv('../data/cleaned_Base.csv')\n",
    "\n",
    "target = 'fraud_bool'\n",
    "X = df.drop(target, axis = 1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                  int64\n",
      "income                                    float64\n",
      "name_email_similarity                     float64\n",
      "current_address_months_count                int64\n",
      "customer_age                                int64\n",
      "days_since_request                        float64\n",
      "payment_type                               object\n",
      "zip_count_4w                                int64\n",
      "velocity_6h                               float64\n",
      "velocity_24h                              float64\n",
      "velocity_4w                               float64\n",
      "bank_branch_count_8w                        int64\n",
      "date_of_birth_distinct_emails_4w            int64\n",
      "employment_status                          object\n",
      "credit_risk_score                           int64\n",
      "email_is_free                               int64\n",
      "housing_status                             object\n",
      "phone_home_valid                            int64\n",
      "phone_mobile_valid                          int64\n",
      "has_other_cards                             int64\n",
      "proposed_credit_limit                     float64\n",
      "foreign_request                             int64\n",
      "source                                     object\n",
      "session_length_in_minutes                 float64\n",
      "device_os                                  object\n",
      "keep_alive_session                          int64\n",
      "device_distinct_emails_8w                   int64\n",
      "month                                       int64\n",
      "prev_address_months_count_ismissing         int64\n",
      "current_address_months_count_ismissing      int64\n",
      "bank_months_count_ismissing                 int64\n",
      "session_length_in_minutes_ismissing         int64\n",
      "device_distinct_emails_8w_ismissing         int64\n",
      "intended_balcon_amount_ismissing            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print all column names and classes of X\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AA', 'AB', 'AC', 'AD', 'AE'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X['payment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132440, 54)\n"
     ]
    }
   ],
   "source": [
    "# Create one-hot encoded version\n",
    "ohe_cols = ['payment_type', \n",
    "            'employment_status', \n",
    "            'housing_status', \n",
    "            'source',\n",
    "            'device_os']\n",
    "\n",
    "X_ohe = pd.get_dummies(X, columns=ohe_cols)\n",
    "\n",
    "# Train on month 0\n",
    "X_ohe_train = X_ohe.loc[X_ohe['month'] == 0]\n",
    "X_ohe_train = X_ohe_train.drop('month', axis = 1)\n",
    "print(X_ohe_train.shape)\n",
    "y_train = y[X_ohe['month'] == 0]\n",
    "\n",
    "# Test on month 1\n",
    "X_ohe_test = X_ohe.loc[X_ohe['month'] == 1]\n",
    "X_ohe_test = X_ohe_test.drop('month', axis = 1)\n",
    "y_test = y[X_ohe['month'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaled version\n",
    "scaler = StandardScaler()\n",
    "X_ohe_train_scaled = scaler.fit_transform(X_ohe_train)\n",
    "X_ohe_test_scaled = scaler.fit_transform(X_ohe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup functions\n",
    "# Create a results dataframe to store and later compare results\n",
    "results = pd.DataFrame()\n",
    "results['Metrics'] = ['True Negatives', 'False Negatives', 'False Positives', 'True Positives', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "\n",
    "def get_metrics(labels, pred_labels):\n",
    "    conf_matrix = np.asarray(confusion_matrix(labels, pred_labels))\n",
    "    metrics = np.concatenate(([accuracy_score(labels, pred_labels)], precision_recall_fscore_support(labels, pred_labels, average='binary')))\n",
    "    return np.concatenate((conf_matrix.reshape(-1),metrics))\n",
    "\n",
    "def fit_model(input_data, model_fn, model_args=None, threshold=None, labels=None):\n",
    "    return model_fn(input_data, model_args, threshold, labels)\n",
    "\n",
    "def predict_model(input_data, model, predict_fn, threshold=None):\n",
    "    return predict_fn(input_data, model, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation forest\n",
    "\n",
    "Uses decision trees: randomly selects a feature and then randomly selects a split value. Theoretically, outliers will need fewer random partitions to be isolated and thus have a shorter path length on the tree.\n",
    "\n",
    "- Scale: no\n",
    "- One-hot encode: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_isolation_forest(input_data, args=None, threshold=None, labels=None):\n",
    "    if threshold == None:\n",
    "        model = IsolationForest()\n",
    "    else:\n",
    "        model = IsolationForest(contamination=threshold)\n",
    "    \n",
    "    model.fit(input_data)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_isolation_forest(input_data, model, threshold=None):\n",
    "    y_pred = model.predict(input_data)\n",
    "    y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of fraud in the entire dataset:  0.011029\n"
     ]
    }
   ],
   "source": [
    "# Calculate the contamination parameter\n",
    "contamination_rate = y.sum() / len(y) # going with overall incidence in the data\n",
    "print(\"Proportion of fraud in the entire dataset: \", contamination_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      " [[121665   4757]\n",
      " [  1095    103]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    126422\n",
      "           1       0.02      0.09      0.03      1198\n",
      "\n",
      "    accuracy                           0.95    127620\n",
      "   macro avg       0.51      0.52      0.51    127620\n",
      "weighted avg       0.98      0.95      0.97    127620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run isolation forest on training data\n",
    "if_model = fit_model(X_ohe_train, fit_isolation_forest, threshold=contamination_rate)\n",
    "\n",
    "if_pred_test = predict_model(X_ohe_test, if_model, predict_isolation_forest)\n",
    "\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(y_test,if_pred_test))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, if_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Isolation Forest'] = get_metrics(y_test, if_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Outlier Factor (LOF)\n",
    "\n",
    "LOF computes the local density deviation of a given data point with respect to its neighbors. If a point has substantially lower density than its neighbors, it is identified as an outlier.\n",
    "\n",
    "The contamination parameter sets the proportion of the most isolated points to be predicted as anomalies, so we want to set that to what we believe the incidence of fraud to be.\n",
    "\n",
    "- Scale: I think so? Gonna do it\n",
    "- One-hot encode: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOF model\n",
    "lof_model = LocalOutlierFactor(n_neighbors = 20,contamination = contamination_rate, novelty=False)\n",
    "# Need to just run it on the testing data and identify the outliers there\n",
    "lof_pred_test = lof_model.fit_predict(X_ohe_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION RESULTS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    126422\n",
      "           1       0.02      0.02      0.02      1198\n",
      "\n",
      "    accuracy                           0.98    127620\n",
      "   macro avg       0.50      0.50      0.50    127620\n",
      "weighted avg       0.98      0.98      0.98    127620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# np.unique(lof_pred_train, return_counts = True)\n",
    "# Recode the predictions\n",
    "lof_pred_test[lof_pred_test == 1] = 0\n",
    "lof_pred_test[lof_pred_test == -1] = 1\n",
    "\n",
    "print('CLASSIFICATION RESULTS')\n",
    "print(classification_report(y_test, lof_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Isolation Forest</th>\n",
       "      <th>LOF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True Negatives</td>\n",
       "      <td>121665</td>\n",
       "      <td>125037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False Negatives</td>\n",
       "      <td>4757</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False Positives</td>\n",
       "      <td>1095</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True Positives</td>\n",
       "      <td>103</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.954145</td>\n",
       "      <td>0.97994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.021193</td>\n",
       "      <td>0.016335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.085977</td>\n",
       "      <td>0.019199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.034005</td>\n",
       "      <td>0.017652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Support</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metrics Isolation Forest       LOF\n",
       "0   True Negatives           121665    125037\n",
       "1  False Negatives             4757      1385\n",
       "2  False Positives             1095      1175\n",
       "3   True Positives              103        23\n",
       "4         Accuracy         0.954145   0.97994\n",
       "5        Precision         0.021193  0.016335\n",
       "6           Recall         0.085977  0.019199\n",
       "7         F1-Score         0.034005  0.017652\n",
       "8          Support             None      None"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['LOF'] = get_metrics(y_test, lof_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture\n",
    "\n",
    "Gaussian mixture models assume all data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. They try to find different subpopulations within the overall dataset.\n",
    "\n",
    "- Scale: eh why not\n",
    "- One-hot encode: yea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gaussian_mixture(input_data, args=None, threshold=None, labels=None):\n",
    "    if threshold == None:\n",
    "        model = GaussianMixture(n_components=2)\n",
    "    else:\n",
    "        model = GaussianMixture(n_components=2, reg_covar=threshold)\n",
    "    \n",
    "    model.fit(input_data)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_gaussian_mixture(input_data, model, threshold=None):\n",
    "    return model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      " [[34781 91641]\n",
      " [  249   949]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.28      0.43    126422\n",
      "           1       0.01      0.79      0.02      1198\n",
      "\n",
      "    accuracy                           0.28    127620\n",
      "   macro avg       0.50      0.53      0.23    127620\n",
      "weighted avg       0.98      0.28      0.43    127620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gm_model = fit_model(X_ohe_train_scaled, fit_gaussian_mixture, None)\n",
    "\n",
    "gm_pred_test = predict_model(X_ohe_test_scaled, gm_model, predict_gaussian_mixture)\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(y_test,gm_pred_test))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, gm_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Isolation Forest</th>\n",
       "      <th>LOF</th>\n",
       "      <th>Gaussian Mixture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True Negatives</td>\n",
       "      <td>121665</td>\n",
       "      <td>125037</td>\n",
       "      <td>34781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False Negatives</td>\n",
       "      <td>4757</td>\n",
       "      <td>1385</td>\n",
       "      <td>91641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False Positives</td>\n",
       "      <td>1095</td>\n",
       "      <td>1175</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True Positives</td>\n",
       "      <td>103</td>\n",
       "      <td>23</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.954145</td>\n",
       "      <td>0.97994</td>\n",
       "      <td>0.279972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.021193</td>\n",
       "      <td>0.016335</td>\n",
       "      <td>0.010249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.085977</td>\n",
       "      <td>0.019199</td>\n",
       "      <td>0.792154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.034005</td>\n",
       "      <td>0.017652</td>\n",
       "      <td>0.020237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Support</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metrics Isolation Forest       LOF Gaussian Mixture\n",
       "0   True Negatives           121665    125037            34781\n",
       "1  False Negatives             4757      1385            91641\n",
       "2  False Positives             1095      1175              249\n",
       "3   True Positives              103        23              949\n",
       "4         Accuracy         0.954145   0.97994         0.279972\n",
       "5        Precision         0.021193  0.016335         0.010249\n",
       "6           Recall         0.085977  0.019199         0.792154\n",
       "7         F1-Score         0.034005  0.017652         0.020237\n",
       "8          Support             None      None             None"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Gaussian Mixture'] = get_metrics(y_test, gm_pred_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
