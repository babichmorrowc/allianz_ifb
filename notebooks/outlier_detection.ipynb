{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty and outlier detection\n",
    "\n",
    "Going through all of the `scikit-learn` methods for outlier detection to see what we get!\n",
    "\n",
    "## Data\n",
    "\n",
    "Import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gower\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I deleted three of the missingness indicators (the ones for the variables that are very rarely missing). I also deleted the `source` column, which is TELEAPP only 0.71% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned data from clean_data.py\n",
    "df = pd.read_csv('../data/cleaned_Base.csv', index_col=0)\n",
    "\n",
    "target = 'fraud_bool'\n",
    "X = df.drop(target, axis = 1)\n",
    "y = df[target]\n",
    "\n",
    "# Drop columns we don't want in the model\n",
    "# Missing flags that the Kaggle guy doesn't use\n",
    "# source\n",
    "cols_to_drop = ['current_address_months_count_ismissing',\n",
    "                'session_length_in_minutes_ismissing',\n",
    "                'device_distinct_emails_8w_ismissing',\n",
    "                'source']\n",
    "X = X.drop(cols_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income                                 float64\n",
      "name_email_similarity                  float64\n",
      "current_address_months_count             int64\n",
      "customer_age                             int64\n",
      "days_since_request                     float64\n",
      "payment_type                            object\n",
      "zip_count_4w                             int64\n",
      "velocity_6h                            float64\n",
      "velocity_24h                           float64\n",
      "velocity_4w                            float64\n",
      "bank_branch_count_8w                     int64\n",
      "date_of_birth_distinct_emails_4w         int64\n",
      "employment_status                       object\n",
      "credit_risk_score                        int64\n",
      "email_is_free                            int64\n",
      "housing_status                          object\n",
      "phone_home_valid                         int64\n",
      "phone_mobile_valid                       int64\n",
      "has_other_cards                          int64\n",
      "proposed_credit_limit                  float64\n",
      "foreign_request                          int64\n",
      "session_length_in_minutes              float64\n",
      "device_os                               object\n",
      "keep_alive_session                       int64\n",
      "device_distinct_emails_8w                int64\n",
      "month                                    int64\n",
      "prev_address_months_count_ismissing      int64\n",
      "bank_months_count_ismissing              int64\n",
      "intended_balcon_amount_ismissing         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print all column names and classes of X\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I one-hot encoded 4 of the variables.\n",
    "\n",
    "For the training set, I filtered to month 0, and then tested on month 1. Based on this, I deleted the month columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903157, 48)\n"
     ]
    }
   ],
   "source": [
    "# Create one-hot encoded version\n",
    "ohe_cols = ['payment_type', \n",
    "            'employment_status', \n",
    "            'housing_status', \n",
    "            # 'source',\n",
    "            'device_os']\n",
    "\n",
    "X_ohe = pd.get_dummies(X, columns=ohe_cols)\n",
    "\n",
    "# Train on month 0\n",
    "X_ohe_train = X_ohe.loc[X_ohe['month'] < 7]\n",
    "X_ohe_train = X_ohe_train.drop('month', axis = 1)\n",
    "print(X_ohe_train.shape)\n",
    "y_train = y[X_ohe['month'] < 7]\n",
    "\n",
    "# Test on month 1\n",
    "X_ohe_test = X_ohe.loc[X_ohe['month'] == 7]\n",
    "X_ohe_test = X_ohe_test.drop('month', axis = 1)\n",
    "y_test = y[X_ohe['month'] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['income', 'name_email_similarity', 'current_address_months_count',\n",
       "       'customer_age', 'days_since_request', 'zip_count_4w', 'velocity_6h',\n",
       "       'velocity_24h', 'velocity_4w', 'bank_branch_count_8w',\n",
       "       'date_of_birth_distinct_emails_4w', 'credit_risk_score',\n",
       "       'email_is_free', 'phone_home_valid', 'phone_mobile_valid',\n",
       "       'has_other_cards', 'proposed_credit_limit', 'foreign_request',\n",
       "       'session_length_in_minutes', 'keep_alive_session',\n",
       "       'device_distinct_emails_8w', 'prev_address_months_count_ismissing',\n",
       "       'bank_months_count_ismissing', 'intended_balcon_amount_ismissing',\n",
       "       'payment_type_AA', 'payment_type_AB', 'payment_type_AC',\n",
       "       'payment_type_AD', 'payment_type_AE', 'employment_status_CA',\n",
       "       'employment_status_CB', 'employment_status_CC', 'employment_status_CD',\n",
       "       'employment_status_CE', 'employment_status_CF', 'employment_status_CG',\n",
       "       'housing_status_BA', 'housing_status_BB', 'housing_status_BC',\n",
       "       'housing_status_BD', 'housing_status_BE', 'housing_status_BF',\n",
       "       'housing_status_BG', 'device_os_linux', 'device_os_macintosh',\n",
       "       'device_os_other', 'device_os_windows', 'device_os_x11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also created scaled versions of the training and testing data. I scaled the variables that were neither Boolean, missingness indicators, nor one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaled version\n",
    "scaler = StandardScaler()\n",
    "# Scale continuous variables\n",
    "# Excluding ohe_cols, bool_cols, and the _ismissing columns\n",
    "bool_cols = ['email_is_free', 'phone_home_valid', 'phone_mobile_valid', 'has_other_cards', 'foreign_request', 'keep_alive_session']\n",
    "cols_to_scale = [col for col in X_ohe_train.columns if \n",
    "                 not col.endswith('_ismissing') \n",
    "                 and col not in ohe_cols\n",
    "                 and col not in bool_cols]\n",
    "\n",
    "# Scale these columns\n",
    "cont_train_scaled = scaler.fit_transform(X_ohe_train[cols_to_scale])\n",
    "cont_test_scaled = scaler.transform(X_ohe_test[cols_to_scale])  # Use transform, not fit_transform on test set\n",
    "\n",
    "# Concatenate scaled and one-hot encoded columns\n",
    "# Columns to add back in\n",
    "cols_not_scaled = [col for col in X_ohe_train.columns if col not in cols_to_scale]\n",
    "X_ohe_train_scaled = np.concatenate((cont_train_scaled, X_ohe_train[cols_not_scaled]), axis = 1)\n",
    "X_ohe_test_scaled = np.concatenate((cont_test_scaled, X_ohe_test[cols_not_scaled]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding some functions to make the metrics nice (stolen from https://github.com/southworks/machine-learning-unsupervised/blob/main/anomaly-detection/fraud_detection.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup functions\n",
    "# Create a results dataframe to store and later compare results\n",
    "results = pd.DataFrame()\n",
    "results['Metrics'] = ['True Negatives', 'False Negatives', 'False Positives', 'True Positives', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Support']\n",
    "\n",
    "def get_metrics(labels, pred_labels):\n",
    "    conf_matrix = np.asarray(confusion_matrix(labels, pred_labels))\n",
    "    metrics = np.concatenate(([accuracy_score(labels, pred_labels)], precision_recall_fscore_support(labels, pred_labels, average='binary')))\n",
    "    return np.concatenate((conf_matrix.reshape(-1),metrics))\n",
    "\n",
    "def fit_model(input_data, model_fn, model_args=None, threshold=None, labels=None):\n",
    "    return model_fn(input_data, model_args, threshold, labels)\n",
    "\n",
    "def predict_model(input_data, model, predict_fn, threshold=None):\n",
    "    return predict_fn(input_data, model, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation forest\n",
    "\n",
    "Uses decision trees: randomly selects a feature and then randomly selects a split value. Theoretically, outliers will need fewer random partitions to be isolated and thus have a shorter path length on the tree.\n",
    "\n",
    "- Scale: no\n",
    "- One-hot encode: yes\n",
    "\n",
    "I found best performance if I don't specify the contamination level and also don't scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_isolation_forest(input_data, args=None, threshold=None, labels=None):\n",
    "    if threshold == None:\n",
    "        model = IsolationForest(**args)\n",
    "    else:\n",
    "        model = IsolationForest(contamination=threshold, **args)\n",
    "    \n",
    "    model.fit(input_data)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_isolation_forest(input_data, model, threshold=None):\n",
    "    y_pred = model.predict(input_data)\n",
    "    y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of fraud in the entire dataset:  0.011029\n"
     ]
    }
   ],
   "source": [
    "# Calculate the contamination parameter\n",
    "contamination_rate = y.sum() / len(y) # going with overall incidence in the data\n",
    "print(\"Proportion of fraud in the entire dataset: \", contamination_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      " [[79818 15597]\n",
      " [ 1078   350]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91     95415\n",
      "           1       0.02      0.25      0.04      1428\n",
      "\n",
      "    accuracy                           0.83     96843\n",
      "   macro avg       0.50      0.54      0.47     96843\n",
      "weighted avg       0.97      0.83      0.89     96843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run isolation forest on training data\n",
    "if_model = fit_model(X_ohe_train\n",
    "                     , fit_isolation_forest\n",
    "                     , model_args = {'max_features': 3.0,\n",
    "                                     'n_estimators': 1000}\n",
    "                    #  , threshold=contamination_rate\n",
    "                     )\n",
    "\n",
    "if_pred_test = predict_model(X_ohe_test, if_model, predict_isolation_forest)\n",
    "\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(y_test,if_pred_test))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, if_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Isolation Forest</th>\n",
       "      <th>LOF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True Negatives</td>\n",
       "      <td>79818</td>\n",
       "      <td>94370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False Negatives</td>\n",
       "      <td>15597</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False Positives</td>\n",
       "      <td>1078</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True Positives</td>\n",
       "      <td>350</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.827814</td>\n",
       "      <td>0.974712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.021948</td>\n",
       "      <td>0.022451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.016807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.040288</td>\n",
       "      <td>0.019223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Support</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metrics Isolation Forest       LOF\n",
       "0   True Negatives            79818     94370\n",
       "1  False Negatives            15597      1045\n",
       "2  False Positives             1078      1404\n",
       "3   True Positives              350        24\n",
       "4         Accuracy         0.827814  0.974712\n",
       "5        Precision         0.021948  0.022451\n",
       "6           Recall         0.245098  0.016807\n",
       "7         F1-Score         0.040288  0.019223\n",
       "8          Support             None      None"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Isolation Forest'] = get_metrics(y_test, if_pred_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Outlier Factor (LOF)\n",
    "\n",
    "LOF computes the local density deviation of a given data point with respect to its neighbors. If a point has substantially lower density than its neighbors, it is identified as an outlier.\n",
    "\n",
    "The contamination parameter sets the proportion of the most isolated points to be predicted as anomalies, so we want to set that to what we believe the incidence of fraud to be.\n",
    "\n",
    "- Scale: I think so? Gonna do it\n",
    "- One-hot encode: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOF model\n",
    "lof_model = LocalOutlierFactor(n_neighbors = 20, # using the default \n",
    "                               contamination = contamination_rate,\n",
    "                               novelty=False)\n",
    "# Need to just run it on the testing data and identify the outliers there\n",
    "lof_pred_test = lof_model.fit_predict(X_ohe_test_scaled)\n",
    "# Try just on first 10000 rows to compare to Gower\n",
    "# lof_pred_test = lof_model.fit_predict(X_ohe_train_scaled[0:10000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION RESULTS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     95415\n",
      "           1       0.02      0.02      0.02      1428\n",
      "\n",
      "    accuracy                           0.97     96843\n",
      "   macro avg       0.50      0.50      0.50     96843\n",
      "weighted avg       0.97      0.97      0.97     96843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# np.unique(lof_pred_train, return_counts = True)\n",
    "# Recode the predictions\n",
    "lof_pred_test[lof_pred_test == 1] = 0\n",
    "lof_pred_test[lof_pred_test == -1] = 1\n",
    "\n",
    "print('CLASSIFICATION RESULTS')\n",
    "print(classification_report(y_test, lof_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Isolation Forest</th>\n",
       "      <th>LOF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True Negatives</td>\n",
       "      <td>76303</td>\n",
       "      <td>94370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False Negatives</td>\n",
       "      <td>19112</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False Positives</td>\n",
       "      <td>1066</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True Positives</td>\n",
       "      <td>362</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.791642</td>\n",
       "      <td>0.974712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.018589</td>\n",
       "      <td>0.022451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.253501</td>\n",
       "      <td>0.016807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.034638</td>\n",
       "      <td>0.019223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Support</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metrics Isolation Forest       LOF\n",
       "0   True Negatives            76303     94370\n",
       "1  False Negatives            19112      1045\n",
       "2  False Positives             1066      1404\n",
       "3   True Positives              362        24\n",
       "4         Accuracy         0.791642  0.974712\n",
       "5        Precision         0.018589  0.022451\n",
       "6           Recall         0.253501  0.016807\n",
       "7         F1-Score         0.034638  0.019223\n",
       "8          Support             None      None"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['LOF'] = get_metrics(y_test, lof_pred_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Gower distance\n",
    "\n",
    "Using the built-in distance metrics for LOF doesn't really make a lot of sense because unfortunately we have a mix of continous and categorical variables. Can we use Gower distance instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just do first 10000 rows because we have to do a big distance matrix\n",
    "X_0 = X.head(10000)\n",
    "X_0 = X_0.drop('month', axis=1)\n",
    "y_0 = y.head(10000)\n",
    "\n",
    "# List the categorical columns\n",
    "cat_cols = X.select_dtypes(exclude='number').columns.tolist()\n",
    "# Add boolean columns and missingness indicators\n",
    "cat_cols = cat_cols + bool_cols + [col for col in X.columns if col.endswith('_ismissing')]\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gower_dist_0 = gower.gower_matrix(X_0, cat_features=[col in cat_cols for col in X_0.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOF model\n",
    "lof_gower = LocalOutlierFactor(n_neighbors = 20, \n",
    "                               contamination = contamination_rate,\n",
    "                               novelty=False,\n",
    "                               metric='precomputed')\n",
    "# Need to just run it on the testing data and identify the outliers there\n",
    "lof_pred_gower = lof_model.fit_predict(gower_dist_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode the predictions\n",
    "lof_pred_gower[lof_pred_gower == 1] = 0\n",
    "lof_pred_gower[lof_pred_gower == -1] = 1\n",
    "\n",
    "print('CLASSIFICATION RESULTS')\n",
    "print(classification_report(y_0, lof_pred_gower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['LOF Gower'] = get_metrics(y_0, lof_pred_gower)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture\n",
    "\n",
    "Gaussian mixture models assume all data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. They try to find different subpopulations within the overall dataset.\n",
    "\n",
    "- Scale: eh why not\n",
    "- One-hot encode: yea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_gaussian_mixture(input_data, args=None, threshold=None, labels=None):\n",
    "#     if threshold == None:\n",
    "#         model = GaussianMixture(n_components=2)\n",
    "#     else:\n",
    "#         model = GaussianMixture(n_components=2, reg_covar=threshold)\n",
    "    \n",
    "#     model.fit(input_data)\n",
    "\n",
    "#     return model\n",
    "\n",
    "# def predict_gaussian_mixture(input_data, model, threshold=None):\n",
    "#     return model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=1)\n",
    "gmm.fit(X_ohe_train_scaled)\n",
    "\n",
    "# Compute log-likelihood on test data\n",
    "gm_loglikelihood = gmm.score_samples(X_ohe_test_scaled)\n",
    "\n",
    "# Set threshold\n",
    "ll_threshold = np.percentile(gm_loglikelihood, 100 * contamination_rate)\n",
    "\n",
    "gm_pred_test = gm_loglikelihood < ll_threshold\n",
    "print('CONFUSION MATRIX:\\n', confusion_matrix(y_test,gm_pred_test))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, gm_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Gaussian Mixture'] = get_metrics(y_test, gm_pred_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
